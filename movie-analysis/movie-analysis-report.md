### Our Current Progress
1. We seccussfully dealed with the part of **vedio segmentation**, using Api (https://www.scenedetect.com/).   
2. We have completed the task of **summarizing a specific segment of the video content** using the API available at https://app.videosummary.io/dashboard.   
3. Currently, we are working on employing the CNN model **VGG-16**, facing some issue of calling GPU (my GPU don't have enough memory for training). We have already collected and labeled the dataset for it. We are thinking if we can **find a trained model** for this task to substitude our model. 
### Experiments
Before confirming the current topic, we have tried the topic of summarizing the content of specific website, object movement detection, recognizing videos generated by AI, randomly generating game scene, and ai generating decoration renderings. 
During the process of achieving this project, we also faced several challenges. First, we find it difficult to work with groups on topics all the time. Our group proposed that the two groups share parts of the video segmentation, and then further develop the subject according to different interest directions. Secondly, there is problem of calling GPU when we tried model VGG-16. This problem is not fixed yet, and we will try to get help from teachers recently.
### Remaining implementation plan 
We plan to train the VGG-16 with the dataset we collected and labeled previously in the following week if my GPU can work well. Also, we will look for models capable of identifying the focal length, angle, motion, and composition of the camera. We will use the films in the film festival of our school last year that were produced by students as the test source. We will use these movies from our film festival in the demo of our project.
### Duties for each group member
- Lloyd Tian: leader, coding.
- Gena Ge: preliminary study (dataset, background, models for scene recognitions), paper work.
- Victor Yu: preliminary study (background, models for videos segmentations), communication.
### **New Modification*
1. Rather than simply recognizing the scenes of camera in movies (for example, medium shot, close up, etc.), we add four more techniques, including the angle, motion, focal length of cameras, and the composition of pictures in the movie. After short researched, we confirmed that the specific model for each technique is not complex, so it is possible for us to include them in our project. **Therefore, we will more focus on implementing these functions than on debuging parameters in our VGG-16-based model.**
2. We reached out to the 12th-grade student responsible for our school's 2023 Film Festival, and he expressed great interest in our project. As a result, we will be utilizing the films created by the festival's students for testing purposes.
